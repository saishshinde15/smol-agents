{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saishshinde15/smol-agents/blob/main/dummy_agent_library(Not_For_Production_Level(Use_For_ChatTemplete).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fr8fVR1J_SdU",
      "metadata": {
        "id": "fr8fVR1J_SdU"
      },
      "source": [
        "# Dummy Agent Library\n",
        "\n",
        "In this simple example, **we're going to code an Agent from scratch**.\n",
        "\n",
        "This notebook is part of the <a href=\"https://www.hf.co/learn/agents-course\">Hugging Face Agents Course</a>, a free Course from beginner to expert, where you learn to build Agents.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png\" alt=\"Agent Course\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ec657731-ac7a-41dd-a0bb-cc661d00d714",
      "metadata": {
        "id": "ec657731-ac7a-41dd-a0bb-cc661d00d714",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install -q huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8WOxyzcmAEfI",
      "metadata": {
        "id": "8WOxyzcmAEfI"
      },
      "source": [
        "## Serverless API\n",
        "\n",
        "In the Hugging Face ecosystem, there is a convenient feature called Serverless API that allows you to easily run inference on many models. There's no installation or deployment required.\n",
        "\n",
        "To run this notebook, **you need a Hugging Face token** that you can get from https://hf.co/settings/tokens. If you are running this notebook on Google Colab, you can set it up in the \"settings\" tab under \"secrets\". Make sure to call it \"HF_TOKEN\".\n",
        "\n",
        "You also need to request access to [the Meta Llama models](meta-llama/Llama-3.2-3B-Instruct), if you haven't done it before. Approval usually takes up to an hour."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf=userdata.get('hf_new')"
      ],
      "metadata": {
        "id": "jlBZF8czsUmg"
      },
      "id": "jlBZF8czsUmg",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5af6ec14-bb7d-49a4-b911-0cf0ec084df5",
      "metadata": {
        "id": "5af6ec14-bb7d-49a4-b911-0cf0ec084df5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# os.environ[\"HF_TOKEN\"]=\"hf_xxxxxxxxxxx\"\n",
        "\n",
        "client = InferenceClient(\"meta-llama/Llama-3.2-3B-Instruct\",api_key=hf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c918666c-48ed-4d6d-ab91-c6ec3892d858",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c918666c-48ed-4d6d-ab91-c6ec3892d858",
        "outputId": "83ea8feb-e4d8-44cf-dca6-60e0e4c8ad54",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " a great way to get started with the basics of photography. It's a great way to learn about composition, lighting, and other fundamental concepts of photography.\n",
            "\n",
            "Here are some tips to get you started with photography:\n",
            "\n",
            "1.  **Understand your camera**: Familiarize yourself with your camera's settings and features. Read the manual or online resources to learn about the different modes, such as manual, aperture priority, and shutter priority.\n",
            "2.  **Practice, practice, practice**: The more you\n"
          ]
        }
      ],
      "source": [
        "# As seen in the LLM section, if we just do decoding, **the model will only stop when it predicts an EOS token**,\n",
        "# and this does not happen here because this is a conversational (chat) model and we didn't apply the chat template it expects.\n",
        "output = client.text_generation(\n",
        "    \"The capital of france is\",\n",
        "    max_new_tokens=100,\n",
        ")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w2C4arhyKAEk",
      "metadata": {
        "id": "w2C4arhyKAEk"
      },
      "source": [
        "As seen in the LLM section, if we just do decoding, **the model will only stop when it predicts an EOS token**, and this does not happen here because this is a conversational (chat) model and **we didn't apply the chat template it expects**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T9-6h-eVAWrR",
      "metadata": {
        "id": "T9-6h-eVAWrR"
      },
      "source": [
        "If we now add the special tokens related to the <a href=\"https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct\">Llama-3.2-3B-Instruct model</a> that we're using, the behavior changes and it now produces the expected EOS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ec0b95d7-8f6a-45fc-b477-c2f95153a001",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec0b95d7-8f6a-45fc-b477-c2f95153a001",
        "outputId": "3e5c87d3-965d-4c9c-e28e-0aec887b1471",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...Paris!\n"
          ]
        }
      ],
      "source": [
        "# If we now add the special tokens related to Llama3.2 model, the behaviour changes and is now the expected oen.\n",
        "prompt=\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "The capital of france is<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "\"\"\"\n",
        "output = client.text_generation(\n",
        "    prompt,\n",
        "    max_new_tokens=100,\n",
        ")\n",
        "\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1uKapsiZAbH5",
      "metadata": {
        "id": "1uKapsiZAbH5"
      },
      "source": [
        "Using the \"chat\" method is a much more convenient and reliable way to apply chat templates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eb536eea-f316-4902-aabd-55710e6c4347",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb536eea-f316-4902-aabd-55710e6c4347",
        "outputId": "4f15db3c-ecbc-4d1e-cbac-3d50bbb23982",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris.\n"
          ]
        }
      ],
      "source": [
        "output = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"The capital of france is\"},\n",
        "    ],\n",
        "    stream=False,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "\n",
        "print(output.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jtQHk9HHAkb8",
      "metadata": {
        "id": "jtQHk9HHAkb8"
      },
      "source": [
        "The chat method is the RECOMMENDED method to use in order to ensure a **smooth transition between models but since this notebook is only educational**, we will keep using the \"text_generation\" method to understand the details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wQ5FqBJuBUZp",
      "metadata": {
        "id": "wQ5FqBJuBUZp"
      },
      "source": [
        "## Dummy Agent\n",
        "\n",
        "In the previous sections, we saw that the **core of an agent library is to append information in the system prompt**.\n",
        "\n",
        "This system prompt is a bit more complex than the one we saw earlier, but it already contains:\n",
        "\n",
        "1. **Information about the tools**\n",
        "2. **Cycle instructions** (Thought → Action → Observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2c66e9cb-2c14-47d4-a7a1-da826b7fc62d",
      "metadata": {
        "id": "2c66e9cb-2c14-47d4-a7a1-da826b7fc62d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This system prompt is a bit more complex and actually contains the function description already appended.\n",
        "# Here we suppose that the textual description of the tools have already been appended\n",
        "SYSTEM_PROMPT = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "get_weather: Get the current weather in a given location\n",
        "\n",
        "The way you use the tools is by specifying a json blob.\n",
        "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
        "\n",
        "The only values that should be in the \"action\" field are:\n",
        "get_weather: Get the current weather in a given location, args: {\"location\": {\"type\": \"string\"}}\n",
        "example use :\n",
        "```\n",
        "{{\n",
        "  \"action\": \"get_weather\",\n",
        "  \"action_input\": {\"location\": \"New York\"}\n",
        "}}\n",
        "\n",
        "ALWAYS use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about one action to take. Only one action at a time in this format:\n",
        "Action:\n",
        "```\n",
        "$JSON_BLOB\n",
        "```\n",
        "Observation: the result of the action. This Observation is unique, complete, and the source of truth.\n",
        "... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $JSON_BLOB must be formatted as markdown and only use a SINGLE action at a time.)\n",
        "\n",
        "You must always end your output with the following format:\n",
        "\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Now begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer. \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UoanEUqQAxzE",
      "metadata": {
        "id": "UoanEUqQAxzE"
      },
      "source": [
        "Since we are running the \"text_generation\" method, we need to add the right special tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "78edbd65-d19b-42ef-8248-e01218470d28",
      "metadata": {
        "id": "78edbd65-d19b-42ef-8248-e01218470d28",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Since we are running the \"text_generation\", we need to add the right special tokens.\n",
        "prompt=f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "{SYSTEM_PROMPT}\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "What's the weather in London ?\n",
        "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L-HaWxinA0XX",
      "metadata": {
        "id": "L-HaWxinA0XX"
      },
      "source": [
        "This is equivalent to the following code that happens inside the chat method :\n",
        "```\n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "    {\"role\": \"user\", \"content\": \"What's the weather in London ?\"},\n",
        "]\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "\n",
        "tokenizer.apply_chat_template(messages, tokenize=False,add_generation_prompt=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4jCyx4HZCIA8",
      "metadata": {
        "id": "4jCyx4HZCIA8"
      },
      "source": [
        "The prompt is now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "Vc4YEtqBCJDK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc4YEtqBCJDK",
        "outputId": "d4416ead-a3c3-43a1-db8e-c79bc3c4cafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "get_weather: Get the current weather in a given location\n",
            "\n",
            "The way you use the tools is by specifying a json blob.\n",
            "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
            "\n",
            "The only values that should be in the \"action\" field are:\n",
            "get_weather: Get the current weather in a given location, args: {\"location\": {\"type\": \"string\"}}\n",
            "example use :\n",
            "```\n",
            "{{\n",
            "  \"action\": \"get_weather\",\n",
            "  \"action_input\": {\"location\": \"New York\"}\n",
            "}}\n",
            "\n",
            "ALWAYS use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about one action to take. Only one action at a time in this format:\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\n",
            "Observation: the result of the action. This Observation is unique, complete, and the source of truth.\n",
            "... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $JSON_BLOB must be formatted as markdown and only use a SINGLE action at a time.)\n",
            "\n",
            "You must always end your output with the following format:\n",
            "\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Now begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer. \n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "What's the weather in London ?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "S6fosEhBCObv",
      "metadata": {
        "id": "S6fosEhBCObv"
      },
      "source": [
        "Let’s decode!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e2b268d0-18bd-4877-bbed-a6b31ed71bc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2b268d0-18bd-4877-bbed-a6b31ed71bc7",
        "outputId": "a0266b94-9e6c-43d6-f612-7bd59e9829d7",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " 1.  **Identify the problem**: The problem is that the text is not providing a clear answer to the question. It's more focused on the process of creating a website.\n",
            " 2.  **Provide a clear answer**: The answer to the question \"can you write a html code for a simple website\" is yes, and here is a simple html code for a website:\n",
            " \n",
            "  ```html\n",
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "    <title>Simple Website</title>\n",
            "</head>\n",
            "<body>\n",
            "    <h1>Welcome to my website</h1>\n",
            "    <p>This is a simple website created using HTML</p>\n",
            "</body>\n",
            "</html>\n",
            "```\n",
            " 3.  **Explain the code**: This HTML code creates a simple website with a title, a heading, and a paragraph of text. The `<!DOCTYPE html>` declaration tells the browser that this is an HTML document. The `<html>` element is the root element of the document\n"
          ]
        }
      ],
      "source": [
        "# Do you see the problem?\n",
        "output = client.text_generation(\n",
        "    prompt,\n",
        "    max_new_tokens=200,\n",
        ")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9NbUFRDECQ9N",
      "metadata": {
        "id": "9NbUFRDECQ9N"
      },
      "source": [
        "Do you see the problem?\n",
        "\n",
        "The **answer was hallucinated by the model**. We need to stop to actually execute the function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9fc783f2-66ac-42cf-8a57-51788f81d436",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fc783f2-66ac-42cf-8a57-51788f81d436",
        "outputId": "9a7e2fe5-6439-4af6-9be5-de013c60d6ae",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It seems like you forgot to include the question about the weather in London. However, I'll provide the answer to the original question about generating 5 prompts for creating hashtags aligned with an academic or professional context.\n",
            "\n",
            "Here are 5 revised prompts:\n",
            "\n",
            "1. **Analyzing the Impact of Social Media on Consumer Behavior**: Create a set of hashtags that can be used to analyze the impact of social media on consumer behavior, including #SocialMediaMarketing, #InfluencerMarketing, #DigitalConsumerism, #OnlineShopping, and #Ecommerce.\n",
            "2. **Designing a Marketing Campaign for a New Product Launch**: Develop a set of hashtags that can be used to promote a new product launch, including #NewProductLaunch, #ProductLaunch, #MarketingCampaign, #Innovation, and #InnovationNation.\n",
            "3. **Understanding the Role of Social Media in Education**: Create a set of hashtags that can be used to discuss the role of social media in education, including #EdTech, #\n"
          ]
        }
      ],
      "source": [
        "# The answer was hallucinated by the model. We need to stop to actually execute the function!\n",
        "output = client.text_generation(\n",
        "    prompt,\n",
        "    max_new_tokens=200,\n",
        "    stop=[\"Observation:\"] # Let's stop before any actual function is called\n",
        ")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yBKVfMIaK_R1",
      "metadata": {
        "id": "yBKVfMIaK_R1"
      },
      "source": [
        "Much Better!\n",
        "\n",
        "Let's now create a **dummy get weather function**. In real situation you could call and API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4756ab9e-e319-4ba1-8281-c7170aca199c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4756ab9e-e319-4ba1-8281-c7170aca199c",
        "outputId": "d0a68fa4-0e29-4764-aebf-8db912a90dab",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the weather in London is sunny with low temperatures. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Dummy function\n",
        "def get_weather(location):\n",
        "    return f\"the weather in {location} is sunny with low temperatures. \\n\"\n",
        "\n",
        "get_weather('London')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IHL3bqhYLGQ6",
      "metadata": {
        "id": "IHL3bqhYLGQ6"
      },
      "source": [
        "Let's concatenate the base prompt, the completion until function execution and the result of the function as an Observation and resume the generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f07196e8-4ff1-41f4-8b2f-99dd550c6b27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f07196e8-4ff1-41f4-8b2f-99dd550c6b27",
        "outputId": "c8a687f5-b956-4d41-ca1b-734a616898f2",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "get_weather: Get the current weather in a given location\n",
            "\n",
            "The way you use the tools is by specifying a json blob.\n",
            "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
            "\n",
            "The only values that should be in the \"action\" field are:\n",
            "get_weather: Get the current weather in a given location, args: {\"location\": {\"type\": \"string\"}}\n",
            "example use :\n",
            "```\n",
            "{{\n",
            "  \"action\": \"get_weather\",\n",
            "  \"action_input\": {\"location\": \"New York\"}\n",
            "}}\n",
            "\n",
            "ALWAYS use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about one action to take. Only one action at a time in this format:\n",
            "Action:\n",
            "```\n",
            "$JSON_BLOB\n",
            "```\n",
            "Observation: the result of the action. This Observation is unique, complete, and the source of truth.\n",
            "... (this Thought/Action/Observation can repeat N times, you should take several steps when needed. The $JSON_BLOB must be formatted as markdown and only use a SINGLE action at a time.)\n",
            "\n",
            "You must always end your output with the following format:\n",
            "\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Now begin! Reminder to ALWAYS use the exact characters `Final Answer:` when you provide a definitive answer. \n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "What's the weather in London ?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "It seems like you forgot to include the question about the weather in London. However, I'll provide the answer to the original question about generating 5 prompts for creating hashtags aligned with an academic or professional context.\n",
            "\n",
            "Here are 5 revised prompts:\n",
            "\n",
            "1. **Analyzing the Impact of Social Media on Consumer Behavior**: Create a set of hashtags that can be used to analyze the impact of social media on consumer behavior, including #SocialMediaMarketing, #InfluencerMarketing, #DigitalConsumerism, #OnlineShopping, and #Ecommerce.\n",
            "2. **Designing a Marketing Campaign for a New Product Launch**: Develop a set of hashtags that can be used to promote a new product launch, including #NewProductLaunch, #ProductLaunch, #MarketingCampaign, #Innovation, and #InnovationNation.\n",
            "3. **Understanding the Role of Social Media in Education**: Create a set of hashtags that can be used to discuss the role of social media in education, including #EdTech, #the weather in London is sunny with low temperatures. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's concatenate the base prompt, the completion until function execution and the result of the function as an Observation\n",
        "new_prompt=prompt+output+get_weather('London')\n",
        "print(new_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cc7Jb8o3Lc_4",
      "metadata": {
        "id": "Cc7Jb8o3Lc_4"
      },
      "source": [
        "Here is the new prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0d5c6697-24ee-426c-acd4-614fba95cf1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d5c6697-24ee-426c-acd4-614fba95cf1f",
        "outputId": "333adad4-057b-4aae-d642-98515eaa4f5a",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " #SocialLearning, #OnlineEducation, #DigitalLearning, #EducationTechnology, and #Foodie.\n",
            "4. **Creating a Brand Identity for a New Restaurant**: Develop a set of hashtags that can be used to promote a new restaurant, including #NewRestaurant, #Foodie, #RestaurantLife, #Branding, #Marketing, and #FoodieFun.\n",
            "5. **Examining the Impact of Climate Change on Global Food Systems**: Create a set of hashtags that can be used to discuss the impact of climate change on global food systems, including #ClimateChange, #FoodSecurity, #Sustainability, #EcoFriendly, #GreenFood, and #FoodForThought.\n",
            "\n",
            "Please let me know if you need any further assistance.\n"
          ]
        }
      ],
      "source": [
        "final_output = client.text_generation(\n",
        "    new_prompt,\n",
        "    max_new_tokens=200,\n",
        ")\n",
        "\n",
        "print(final_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JaYraLlWtXfE"
      },
      "id": "JaYraLlWtXfE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}